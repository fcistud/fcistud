# Mariam Hassan

AI Researcher | DeepMind Scholar | Foundation Models, Multimodal AI, and Mechanistic Interpretability

## About
AI researcher and DeepMind Scholar with experience in foundation models, LLMs, and multimodal learning. Completed an MSc in Artificial Intelligence for Biomedicine and Healthcare at UCL with Distinction. I build and adapt generative and multimodal model architectures for large, complex biomedical data, optimize LLM components, and work on automated mechanistic interpretability and AI safety-aligned research workflows.

## Current Focus
- AutoMechInterp: A deterministic stage-gate benchmark for mechanistic-interpretability claims.
- Mechanistic interpretability research agent for reproducible experimentation and evaluation workflows.

## Featured Project
- Website: https://fcistud.github.io/mechanistic-interpretability/
- Repository: https://github.com/fcistud/mechanistic-interpretability

## Research Interests
- AI safety
- Automating AI alignment and safety research
- Automated mechanistic interpretability
- AI for science
- AI for accelerating scientific discovery
- AI for biomedicine
- AI for healthcare
- Neuromorphic computing and AI
- Neurosymbolic AI
- Whole-brain emulation
- World models

## Selected Skills
- Python
- C++
- Java
- R
- Julia
- MATLAB
- SQL
- Bash
- PyTorch
- TensorFlow
- JAX
- Hugging Face Transformers
- Tokenizers
- Diffusion Models

## Certifications
- Microsoft Certified: Azure AI Engineer Associate
- Azure Responsible AI Workshop Coach
- AWS Certified Cloud Practitioner
- AWS Certified AI Practitioner - Subject Matter Expert Contributor
- AI Safety Fundamentals - BlueDot Impact
- AI Safety, Ethics and Society - Center for AI Safety
- Machine Learning and Deep Learning Specialization - DeepLearning.AI
- AI for Medicine Specialization - DeepLearning.AI

## Contact
- Email: mariam.ihab.mo@gmail.com
- LinkedIn: https://www.linkedin.com/in/mariam-ihab-mohammed/
- GitHub: https://github.com/fcistud
- Personal website: https://fcistud.github.io

